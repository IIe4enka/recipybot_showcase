import streamlit as st
from openai import OpenAI
import uuid

LLM_SYSTEM_PROMPT_STRING = '''A client is contacting you to get recommendations on food recipies and ingredients and then buy them through our website.
You must act as a friendly agent that recommends the user food recipies for any dish. Go step by step:
1. If the user specifically asked for a particular dish - write the recipy and all the ingredients
2. If not, give the user general ideas for the dish and ingredients required, but not the recipy itself
3. When the user agrees with your recommendation or asks for a specific dish or course of dishes - write the recipy and all the ingredients

Ask the user additional questions if you are not completely sure what they would like. You can even create new recipies if the client specifically asks for this.
Your job is to make the customer satisfied and help them order the best products for their recipie. Think step by step, iterate and display your thoughts on what to answer.

After you prodive the user with a recipy, at the end of the message add a list of ingridients.
Format it like this: –ò–Ω–≥—Ä–∏–¥–∏–µ–Ω—Ç—ã: ['–ª—É–∫', '—á–µ—Å–Ω–æ–∫']

If the user asks to finish or add their recipies to the cart - reply with a following json:
{ 'title': '–ü–µ–ª—å–º–µ–Ω–∏ —Å –≥–æ–≤—è–¥–∏–Ω–æ–π', 'ingridients':['–ª—É–∫', '—á–µ—Å–Ω–æ–∫'] }

Do not talk about anything other than culinary, food and recipies. Always respond in Russian language.
'''

def chat_page():    
    st.title("üöÄ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤–æ –í–∫—É—Å–æ–ë–æ—Ç! üöÄ")
    st.caption("–ó–Ω–∞–∫–æ–º—å—Ç–µ—Å—å, –≤–∞—à –ª–∏—á–Ω—ã–π –∫—É–ª–∏–Ω–∞—Ä–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç –∫–∞–∂–¥—ã–π –≤–∞—à —É–∂–∏–Ω –≤ –Ω–∞—Å—Ç–æ—è—â–µ–µ –∫—É–ª–∏–Ω–∞—Ä–Ω–æ–µ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–µ! üç≤üåç")
    st.caption("–ß—Ç–æ —É–º–µ–µ—Ç –í–∫—É—Å–æ–ë–æ—Ç? ü§ñ")
    st.caption("üìú –ü–æ–¥–±–æ—Ä –†–µ—Ü–µ–ø—Ç–æ–≤: –ù–∞–π–¥–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ–µ –±–ª—é–¥–æ –Ω–∞ –ª—é–±–æ–π –≤–∫—É—Å –∏ —Å–ª—É—á–∞–π, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –≤–∞—à–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö –∏ –∏–º–µ—é—â–∏—Ö—Å—è –ø—Ä–æ–¥—É–∫—Ç–∞—Ö!")
    st.caption("üõí –°–ø–∏—Å–æ–∫ –ü–æ–∫—É–ø–æ–∫: –°–æ–∑–¥–∞—Å—Ç –¥–ª—è –≤–∞—Å —Å–ø–∏—Å–æ–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ –∏ –ø–æ–º–æ–∂–µ—Ç –∏—Ö –∑–∞–∫–∞–∑–∞—Ç—å —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π –ø—Ä—è–º–æ –Ω–∞ –≤–∞—à –ø–æ—Ä–æ–≥!")
    st.caption("üç≤ –ö—É–ª–∏–Ω–∞—Ä–Ω—ã–µ –°–æ–≤–µ—Ç—ã: –ü–æ–¥–µ–ª–∏—Ç—Å—è —Ö–∏—Ç—Ä–æ—Å—Ç—è–º–∏ –∏ —Å–µ–∫—Ä–µ—Ç–∞–º–∏ –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è, –ø–æ–º–æ–≥–∞—è —Å—Ç–∞—Ç—å –Ω–∞—Å—Ç–æ—è—â–∏–º —à–µ—Ñ-–ø–æ–≤–∞—Ä–æ–º —É —Å–µ–±—è –¥–æ–º–∞!")

    if "api_key" not in st.session_state:
        st.session_state.api_key = ""

    with st.sidebar:
        st.session_state.api_key = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à OpenAI API Key:")
        
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞"):
            st.session_state.messages = []


    if st.session_state.api_key:
        client = OpenAI(api_key=st.session_state.api_key)

    else:
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–∞—à OpenAI API Key –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã —Å –í–∫—É—Å–æ–ë–æ—Ç.")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "session_id" not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Hello?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
    
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            openai_msgs = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
            openai_msgs.append({"role": "system", "content": LLM_SYSTEM_PROMPT_STRING})
            # openai_msgs.append({"role": "system", "content": retrieved_data})
            for response in client.chat.completions.create(
                model='gpt-4-1106-preview',
                messages=openai_msgs,
                stream=True,
            ):
                full_response += (response.choices[0].delta.content or "") 
                message_placeholder.markdown(full_response + "‚ñå")
            message_placeholder.markdown(full_response)
            #response = client.chat.completions.create(model=LLM_FASTEST_MODEL,messages=[{"role": "assistant", "content": LLM_PRODUCTS_PROMPT}, {"role": "user", "content": full_response}])
            #retrieved_docs = vector_search(query=response.choices[0].message.content, collection_name="product_table", k_query=1)
            #retrieved_ids = [doc.metadata['id'] for doc in retrieved_docs]

        st.session_state.messages.append({"role": "assistant", "content": full_response})


if __name__ == '__main__':
    chat_page()
